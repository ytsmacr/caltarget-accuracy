{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed8d116a-3b84-432c-9f23-2f73d07053b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "#https://hst-docs.stsci.edu/hstdhb/4-hst-data-analysis/4-4-working-with-fits-data-in-python\n",
    "\n",
    "import requests\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7234ea4c-f830-4298-b894-ec825e1785c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter root folder path for data to be saved:  C:\\Users\\ytsma22c\\Documents\\GitHub\\caltarget-accuracy\\extract data from PDS\\new - refresh\\test\n"
     ]
    }
   ],
   "source": [
    "# prep \n",
    "date = datetime.datetime.now().strftime(\"%d%m%y\")\n",
    "\n",
    "parent_url = 'https://pds-geosciences.wustl.edu/m2020/urn-nasa-pds-mars2020_supercam/data_calibrated_spectra/'\n",
    "\n",
    "folder = input('Enter root folder path for data to be saved: ')\n",
    "laser_folder = f'{folder}\\\\LIBS RDR laser data'\n",
    "spectra_folder = f'{folder}\\\\LIBS RDR spectra'\n",
    "fits_folder = f'{folder}\\\\LIBS RDR fits files'\n",
    "\n",
    "meta_path = f'{folder}\\\\LIBS_RDR_metadata_{date}.csv'\n",
    "meta_comps_path = f'{folder}\\\\LIBS_RDR_metadata_w_pred_comps_{date}.csv'\n",
    "spectra_path = f'{folder}\\\\LIBS_RDR_mean_spectra_{date}.csv'\n",
    "\n",
    "#****spectra = pd.read_csv(spectra_path)\n",
    "\n",
    "# first, update comps file\n",
    "comps = pd.read_csv('https://pds-geosciences.wustl.edu/m2020/urn-nasa-pds-mars2020_supercam/data_derived_spectra/supercam_libs_moc.csv')\n",
    "comps_path =  f'{folder}\\\\supercam_libs_moc_{date}.csv'\n",
    "comps.to_csv(comps_path, index=False)\n",
    "\n",
    "# drop header\n",
    "comps = comps.iloc[7:].copy()\n",
    "comps.columns = list(comps.iloc[0])\n",
    "comps.drop(index=7, inplace=True)\n",
    "comps.reset_index(inplace=True, drop=True)\n",
    "comps.rename(columns={'cdr_fname':'pkey'}, inplace=True)\n",
    "# add version 01 to make match meta values\n",
    "comps['pkey'] = [x+'01' for x in comps.pkey]\n",
    "\n",
    "# get page contents\n",
    "page = requests.get(parent_url).text\n",
    "\n",
    "# get sol pages\n",
    "def get_sol_no(sol_page):\n",
    "    return int(sol_page.split('_')[1])\n",
    "\n",
    "def no_to_sol(sol_no):\n",
    "    n_zeros = 5 - len(str(sol_no))\n",
    "    sol = 'sol_'+(n_zeros*'0')+str(sol_no)\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a79b3078-fb4c-4bd4-844d-e3b4cffe426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_pages = list(set(re.findall(r'sol_\\d{5}', page)))\n",
    "sol_pages.sort()\n",
    "sol_page_nos = [get_sol_no(i) for i in sol_pages]\n",
    "\n",
    "# find which data needs adding\n",
    "def get_sols_to_add():\n",
    "    global meta_path, sol_page_nos\n",
    "    \n",
    "    # if already exists because the run broke\n",
    "    if os.path.exists(meta_path):\n",
    "        meta = pd.read_csv(meta_path)\n",
    "        most_recent_sol_no = max(meta['sol'])\n",
    "        most_recent_sol = no_to_sol(most_recent_sol_no)\n",
    "        sol_to_add = [i for i in sol_pages if i > most_recent_sol]\n",
    "        sol_to_add.sort()\n",
    "        \n",
    "    # to initiate\n",
    "    else:\n",
    "        meta = pd.DataFrame(columns=['pkey',\n",
    "                                     'sol',\n",
    "                                     'sclock',\n",
    "                                     'seq_n',\n",
    "                                     'target',\n",
    "                                     'location_n',\n",
    "                                     'producer',\n",
    "                                     'version'])\n",
    "        sol_to_add = sol_pages\n",
    "        \n",
    "    return sol_to_add, meta\n",
    "\n",
    "sols_to_add, meta = get_sols_to_add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91e51ec7-ae88-4fa6-963e-009cf9a2a799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pkey</th>\n",
       "      <th>sol</th>\n",
       "      <th>sclock</th>\n",
       "      <th>seq_n</th>\n",
       "      <th>target</th>\n",
       "      <th>location_n</th>\n",
       "      <th>producer</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pkey, sol, sclock, seq_n, target, location_n, producer, version]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
