{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66448295-b705-40c9-bb2f-db6a56ab812a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nby Cai Ytsma\\nlast updated 20 April 2023\\n\\nAutomatically extract LIBS CCS data from ChemCam PDS\\n\\nInformation: \\nhttps://pds.nasa.gov/ds-view/pds/viewProfile.jsp?dsid=MSL-M-CHEMCAM-LIBS-4/5-RDR-V1.0\\n(MOC based on 'mean' CCS spectra)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "'''\n",
    "by Cai Ytsma\n",
    "last updated 20 April 2023\n",
    "\n",
    "Automatically extract LIBS CCS data from ChemCam PDS\n",
    "\n",
    "Information: \n",
    "https://pds.nasa.gov/ds-view/pds/viewProfile.jsp?dsid=MSL-M-CHEMCAM-LIBS-4/5-RDR-V1.0\n",
    "(MOC based on 'mean' CCS spectra)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88233f59-6fc5-44f7-a17e-6673fcdc06fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter root folder path for data to be saved:  C:\\Users\\ytsma22c\\Documents\\GitHub\\caltarget-accuracy\\extract data from PDS\\new - refresh\\test\n"
     ]
    }
   ],
   "source": [
    "#---------------#\n",
    "#  ADD SPECTRA  #\n",
    "#---------------#\n",
    "# prep\n",
    "date = datetime.datetime.now().strftime(\"%d%m%y\")\n",
    "\n",
    "folder = input('Enter root folder path for data to be saved: ')\n",
    "meta_path = f'{folder}\\\\LIBS_CCS_metadata_{date}.csv'\n",
    "spectra_path = f'{folder}\\\\LIBS_CCS_mean_spectra_{date}.csv'\n",
    "\n",
    "# get page info\n",
    "parent_url = 'https://pds-geosciences.wustl.edu/msl/msl-m-chemcam-libs-4_5-rdr-v1/mslccm_1xxx/data/'\n",
    "# get page contents\n",
    "page = requests.get(parent_url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eccc8d0-3c5e-4b49-90a8-538b434eac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sol pages\n",
    "sol_pages = list(set(re.findall(r'sol\\d{5}', page)))\n",
    "sol_page_nos = [int(i[3:]) for i in sol_pages]\n",
    "sol_page_nos.sort()\n",
    "\n",
    "def no_to_sol(sol_no):\n",
    "    n_zeros = 5 - len(str(sol_no))\n",
    "    sol = 'sol'+(n_zeros*'0')+str(sol_no)\n",
    "    return sol\n",
    "\n",
    "# find which data needs adding\n",
    "def get_sols_to_add():\n",
    "    global meta_path, sol_page_nos\n",
    "    \n",
    "    # if already exists because the run broke\n",
    "    if os.path.exists(meta_path):\n",
    "        meta = pd.read_csv(meta_path)\n",
    "        most_recent_sol_no = max(meta['sol'])\n",
    "        sol_to_add = [no_to_sol(i) for i in sol_page_nos if i > most_recent_sol_no]\n",
    "        sol_to_add.sort()\n",
    "        return sol_to_add, meta\n",
    "    \n",
    "    # to initiate\n",
    "    else:\n",
    "        meta = pd.DataFrame(columns=['pkey','sol'])\n",
    "        sol_to_add = [no_to_sol(i) for i in sol_page_nos]\n",
    "        \n",
    "    return sol_to_add, meta\n",
    "\n",
    "sols_to_add, meta = get_sols_to_add()\n",
    "\n",
    "def make_meta(meta_list):\n",
    "    global meta, meta_path\n",
    "    meta_to_add = pd.DataFrame(meta_list, columns = ['pkey','sol'])\n",
    "    updated_meta = pd.concat([meta,meta_to_add], ignore_index=True).drop_duplicates(ignore_index=True)\n",
    "    updated_meta.to_csv(meta_path, index=False)\n",
    "    return updated_meta\n",
    "\n",
    "def make_spectra(spectra_to_add):\n",
    "    global spectra_path\n",
    "    \n",
    "    # if already exists because the run broke\n",
    "    if os.path.exists(spectra_path):\n",
    "        global spectra\n",
    "        updated_spectra = spectra.merge(spectra_to_add)\n",
    "    # to initiate\n",
    "    else:\n",
    "        updated_spectra = spectra_to_add.copy()\n",
    "        \n",
    "    updated_spectra.to_csv(spectra_path, index=False)\n",
    "        \n",
    "    return updated_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e79ee701-fafb-403b-a3dd-b49b1434af29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "new sols: 100%|██████████████████████████████████████████████████████████████████████████| 5/5 [00:31<00:00,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 spectra from 5 sols added\n",
      "Spectra data extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cont = True if len(sols_to_add) > 0 else False\n",
    "\n",
    "while cont:\n",
    "    try:\n",
    "        meta_list = []\n",
    "        count=0\n",
    "        scount=0\n",
    "        for sol in tqdm(sols_to_add[:5], desc='new sols'):\n",
    "            sol_page = requests.get(f'{parent_url}{sol}').text\n",
    "            ccs_files = list(set(re.findall('.{13}ccs_.{19}\\.csv', sol_page)))\n",
    "\n",
    "            for filename in ccs_files:\n",
    "\n",
    "                pkey = filename[:-4]\n",
    "\n",
    "                s = pd.read_csv(f'{parent_url}{sol}/{filename}', \n",
    "                                skiprows=16)\n",
    "                s.columns = [c.strip() for c in list(s.columns)]\n",
    "\n",
    "                if count == 0:\n",
    "                    spectra_to_add = s[['# wave','mean']].copy()\n",
    "                    spectra_to_add.columns = ['wave', pkey]\n",
    "                else:\n",
    "                    spectra_to_add[pkey] = s['mean'].values\n",
    "\n",
    "                meta_list.append([pkey, int(sol[3:])])\n",
    "                count+=1 \n",
    "            scount+=1 \n",
    "\n",
    "        # export complete dfs\n",
    "        meta = make_meta(meta_list)\n",
    "        spectra = make_spectra(spectra_to_add)\n",
    "        print(f'{count} spectra from {scount} sols added')\n",
    "        cont=False\n",
    "\n",
    "    except:\n",
    "        # export what it got up to\n",
    "        meta = make_meta(meta_list)\n",
    "        spectra = make_spectra(spectra_to_add)\n",
    "        print(f'{count} spectra from {scount} sols added')\n",
    "        \n",
    "        # prep for next iteration\n",
    "        sols_to_add, meta = get_sols_to_add()\n",
    "        if len(sols_to_add) == 0:\n",
    "            cont = False\n",
    "        \n",
    "print('Spectra data extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0059263-0e68-47f5-9ea7-8f2e44279242",
   "metadata": {},
   "outputs": [],
   "source": [
    "sols_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f24b4f58-1537-4c20-a705-00e27a5d675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/32 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'moc_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource File\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m moc[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m(moc_df\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(moc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhas different format\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m     display(moc_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'moc_df' is not defined"
     ]
    }
   ],
   "source": [
    "#---------------#\n",
    "#    ADD MOC    #\n",
    "#---------------#\n",
    "moc_outpath = f'{folder}\\\\moc_composite_{date}.csv'\n",
    "\n",
    "# get those on the page\n",
    "moc_path = parent_url+'moc/'\n",
    "moc_page = requests.get(moc_path).text\n",
    "moc_files = set(re.findall('moc.{10}\\.csv', moc_page))\n",
    "\n",
    "\n",
    "for moc in tqdm(moc_files):\n",
    "    df = pd.read_csv(moc_path+moc, skiprows=6)\n",
    "\n",
    "    # format\n",
    "    # remove +/- columns\n",
    "    df = df[[c for c in df.columns if '+/-' not in c]]\n",
    "    # add pkey column\n",
    "    df.insert(0,'pkey',[p[:-4].lower() for p in df.File])\n",
    "    # don't need File anymore\n",
    "    df.drop(columns='File', inplace=True)\n",
    "    df['Source File'] = moc[:-4]\n",
    "\n",
    "    if count == 0:\n",
    "        new_moc = df.copy()\n",
    "    else:\n",
    "        new_moc = pd.concat([new_moc, df], ignore_index=True)\n",
    "    count+=1\n",
    "\n",
    "# export\n",
    "new_moc.to_csv(moc_outpath, index=False)\n",
    "    \n",
    "print('MOC data extracted')\n",
    "    \n",
    "#-----------------#\n",
    "# ADD MOC TO META #\n",
    "#-----------------#\n",
    "meta_moc_path = f'{folder}\\\\LIBS_CCS_metadata_w_moc_{date}.csv'\n",
    "meta_moc = meta.merge(new_moc)\n",
    "meta_moc.to_csv(meta_moc_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
